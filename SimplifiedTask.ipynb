{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimplifiedTask.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTq+Mpjq8cJEcIsqSVrPnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nptikiran/Linkedin_Google_ProfileScraper/blob/main/SimplifiedTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51UPKrR1PwD9"
      },
      "source": [
        "Task 1 - Create a POST API to scrape data of 100 profiles from LinkedIn and then store them in a mongo database. The API should accept a search query as input in its request body, based on which it should filter out the profiles to be scrapped. \n",
        "Task 2 - Create a GET API to retrieve scrapped data from the mongo database. The API should accept as input the number of results to display as query params.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blR7vEglPuoF"
      },
      "source": [
        "!pip install ipython \n",
        "!pip install selenium  \n",
        "!pip install time \n",
        "!pip install parsel\n",
        "!pip install csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5D-rNY0mRt"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import random\n",
        "from math import *\n",
        "import operator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option(\"display.max_columns\", 10000)\n",
        "import string\n",
        "from pprint import pprint\n",
        "from scipy import stats\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# import plotting libraries\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import style\n",
        "%matplotlib inline \n",
        "\n",
        "import graphviz \n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "# datasets\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import load_svmlight_files\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Load libraries\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# import libraries for model validation\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import LeaveOneOut \n",
        "\n",
        "# import libraries for metrics and reporting\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from sklearn.model_selection import validation_curve\n",
        "from scipy.sparse import vstack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2ylhHPUTKJZ"
      },
      "source": [
        "# import web driver\n",
        "from selenium import webdriver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCjAm3XxUJdz"
      },
      "source": [
        "# specifies the path to the chromedriver.exe\n",
        "driver = webdriver.Chrome('~\\C:\\WebDriver')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1yCbY6RUwJI"
      },
      "source": [
        "# driver.get method() will navigate to a page given by the URL address\n",
        "driver.get('https://www.linkedin.com')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGTbQlF8vTdM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}